import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.datasets import load_breast_cancer

SEED = 42

URL: "https://raw.githubusercontent.com/datasets/breast-cancer-wisconsin/master/data/data.csv"

cancer = load_breast_cancer()
x = pd.DataFrame(cancer.data, columns=cancer.feature_names)
y = pd.Series(cancer.target)

print(x.head())
print(y.head())

plt.figure(figsize=(22, 22))
sns.heatmap(x.corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Matriz de correlacion paara el descarte de modelos")
plt.show()

#Hay que hacer el AUC para ir descartando codigos
x_train, x_test, y_train, y_test = train_test_split(
    x,
    y,
    test_size=0.2,
    random_state = SEED
)

#Escalamiento
scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled = scaler.transform(x_test)

def evaluar_modelo(modelo, x_test, y_test):
    pred = modelo.predict(x_test)
    return accuracy_score(y_test, pred) 

resultados = {}
SEED = 42 

#1.- Modelo de Naive Bayes 
nb_model = GaussianNB()
nb_model.fit(x_train_scaled, y_train)
resultados["Naive Bayes"] = evaluar_modelo(nb_model, x_test_scaled, y_test)

#2.- Modelo de KNN vecinos o neightbors
knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(x_train_scaled, y_train)
resultados["KNN"] = evaluar_modelo(knn_model, x_test_scaled, y_test)

#3.- Modelo de regresion logistica
log_model = LogisticRegression(solver="liblinear", random_state=SEED)
log_model.fit(x_train_scaled, y_train)
resultados["Regresión Logística"] = evaluar_modelo(log_model, x_test_scaled, y_test)

#4.- Modelo del arbol de decisiones
tree_model = DecisionTreeClassifier(random_state=SEED)
tree_model.fit(x_train_scaled, y_train)
resultados["Árbol de Decisión"] = evaluar_modelo(tree_model, x_test_scaled, y_test)

df_resultados = pd.DataFrame(list(resultados.items()), columns=["Modelo", "Precisión"])
df_resultados = df_resultados.sort_values(by="Precisión", ascending=False)

print("\n--- Precisión de los Modelos ---")
print(df_resultados.set_index("Modelo"))

#El modelo que vamos a utilizar es el de regresion logisitca por que es el que mas alta (AUC) nos dio
#Dividir lso datos de entrenamiento y de prueba 

print("-"*30)
print("Utilizamos el model de regresion logisitca")
print("Datos divididos")

print("Visualizacion de los datos de entrenamiento:", x_train.shape[0],"seleccionamos:", x_train.shape[1])
print("Visualizacion de los datos de prueba:", x_test.shape[0],"seleccionamos:", x_test.shape[1])

# 3. Predecir en el conjunto de prueba escalado
y_pred = log_model.predict(x_test_scaled)

# Evaluacion 
# 4. Precisión 
accuracy = accuracy_score(y_test, y_pred)
print("-"*30)
print(" Precisión del Modelo de Regresión Logística: %.4f" % accuracy)

# 5. Reporte de Clasificación
# Precion,recall (0=Benigno, 1=Maligno)
print("\n--- Reporte de Clasificación ---")
print(classification_report(y_test, y_pred))

# 6. Matriz de Confusión
print("\n--- Matriz de Confusión  ---")
conf_matrix = confusion_matrix(y_test, y_pred)
print(conf_matrix)

# Visualizacion
plt.figure(figsize=(6, 5))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['Benigno', 'Maligno'], yticklabels=['Benigno', 'Maligno'])
plt.ylabel('Valores Reales')
plt.xlabel('Predicciones ')
plt.title('Matriz de Confusión')
plt.show()
